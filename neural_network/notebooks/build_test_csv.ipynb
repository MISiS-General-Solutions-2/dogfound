{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cd1cbbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: целевой путь «../yolov5» уже существует и не является пустым каталогом.\r\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/ultralytics/yolov5 ../yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c68ceaa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os, sys\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import math\n",
    "from torch import nn\n",
    "from torchvision import models\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28fea5cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6e5e47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../yolov5/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ab7e383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# yolo_model = torch.hub.load('ultralytics/yolov5', 'custom', path='../models/detect/yolo_finetuned_v1.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8aac317b",
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_model = torch.load('../models/detect/yolo_finetuned_v2.pt')['model'].float().eval().autoshape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11297511",
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_model = yolo_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1256c81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# yolo_model(np.random.randn(3, 640, 640)).pandas().xywh[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8930ea72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5ea0b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiOutputModel(nn.Module):\n",
    "    def __init__(self, n_color_classes=3, n_tail_classes=2):\n",
    "        super().__init__()\n",
    "        self.resnet = models.resnet34(pretrained=False)\n",
    "        self.base_model = nn.Sequential(\n",
    "            *(list(self.resnet.children())[:-1])\n",
    "        )  # take the model without classifier\n",
    "\n",
    "        last_channel = (\n",
    "            models.resnet34().fc.in_features\n",
    "        )  # size of the layer before the classifier\n",
    "\n",
    "        # create separate classifiers for our outputs\n",
    "        self.color = nn.Sequential(\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(in_features=last_channel, out_features=n_color_classes),\n",
    "        )\n",
    "        self.tail = nn.Sequential(\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(in_features=last_channel, out_features=n_tail_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.base_model(x)\n",
    "\n",
    "        # reshape from [batch, channels, 1, 1] to [batch, channels] to put it into classifier\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        return {\n",
    "            \"color\": self.color(x),\n",
    "            \"tail\": self.tail(x),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a832d19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_model = MultiOutputModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "396ccaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_model = classifier_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bde531c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "weigths = torch.load('../models/classifier/resnet.pt')['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "527d2a3f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_model.load_state_dict(weigths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e1132e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_pipe = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406),\n",
    "                         (0.229, 0.224, 0.225)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "402c3286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tr_pipe(torch.from_numpy(np.random.rand(3, 640, 640).astype(np.uint8)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b81ce880",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_folder = '../test_images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0208ee2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../test_images/А94.jpg',\n",
       " '../test_images/С69.jpg',\n",
       " '../test_images/С47.jpg',\n",
       " '../test_images/B60.jpg',\n",
       " '../test_images/А41.jpg']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images = [os.path.join(images_folder, path) for path in os.listdir(images_folder)]\n",
    "images[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f10f2bf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['..', 'test_images', 'С10.jpg']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.split('/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2efbcdda",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dicts = []\n",
    "for image in images:\n",
    "    attr_dict = {'filename': image.split('/')[-1], 'is_animal_there': 0, 'is_it_a_dog': 0, 'is_the_owner_there': 0, 'color': 0, 'tail': 0}\n",
    "    cv_image = cv2.imread(image)\n",
    "    cv_image = cv2.cvtColor(cv_image, cv2.COLOR_BGR2RGB)\n",
    "    res_df = yolo_model(cv_image).pandas().xywh[0]\n",
    "    animals = res_df.query(\"name=='dog' or name=='cat' or name=='bird'\")\n",
    "    if len(animals) > 0:\n",
    "        attr_dict['is_animal_there'] = 1\n",
    "        dogs = res_df.query(\"name=='dog'\")\n",
    "        if len(dogs) > 0:\n",
    "            attr_dict['is_it_a_dog'] = 1\n",
    "            best_dog = dogs.sort_values(by='confidence', ascending=False).iloc[0]\n",
    "            coords = (int(best_dog['ycenter']-best_dog['height']//2),\n",
    "                      int(best_dog['ycenter']+best_dog['height']//2), \n",
    "                      int(best_dog['xcenter']-best_dog['width']//2),\n",
    "                      int(best_dog['xcenter']+best_dog['width']//2))\n",
    "            dog_crop = cv_image[coords[0]:coords[1], coords[2]:coords[3]]\n",
    "            classes = classifier_model(tr_pipe(dog_crop).unsqueeze(0).to(device))\n",
    "            color_cl = classes['color'].argmax().cpu().detach().item() + 1\n",
    "            tail_cl = classes['tail'].argmax().cpu().detach().item() + 1\n",
    "            attr_dict['color'] = color_cl\n",
    "            attr_dict['tail'] = tail_cl\n",
    "            humans = res_df.query(\"name=='person'\")\n",
    "            if len(humans) > 0:\n",
    "                best_dog_coords = best_dog['xcenter'] ,best_dog['ycenter']\n",
    "                for i, r in persons.iterrows():\n",
    "                    person_coords = r['xcenter'], r['ycenter']\n",
    "                    dist = math.dist(person_coords, best_dog_coords)\n",
    "                    if dist <= 300:\n",
    "                        attr_dict['is_the_owner_there'] = 1\n",
    "    all_dicts.append(attr_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "75cdf666",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(all_dicts).to_csv('test_results_4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2436622c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
